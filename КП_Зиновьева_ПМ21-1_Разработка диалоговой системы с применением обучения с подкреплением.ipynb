{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from torch.nn import Sequential\nfrom torch.nn import Linear\nfrom torch.nn import ReLU\nfrom torch.nn import MSELoss\nimport torch\nimport torch.optim.optimizer as optim\nfrom torch.optim import Adam\nimport random, copy\nimport numpy as np\n\nimport re\n\nfrom sklearn import preprocessing\n\nfrom collections import defaultdict\nfrom tqdm.notebook import tqdm \nimport wandb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-12T17:55:33.460894Z","iopub.execute_input":"2023-05-12T17:55:33.461344Z","iopub.status.idle":"2023-05-12T17:55:39.852045Z","shell.execute_reply.started":"2023-05-12T17:55:33.461310Z","shell.execute_reply":"2023-05-12T17:55:39.850961Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"'PLACEHOLDER'  # информационные слоты\n'UNK'  # слоты запросоы\n'anything'  # любая информация для слота запроса уместна\n'no match available'  # в базе данных не нашлйо совпадений для цели\n\n# Типы возможных действий\nusersim_intents = ['inform', 'request', 'thanks', 'reject', 'done']\n\n# Главная цель диалога \nusersim_default_key = 'Model'\n\n# Обязательный запросовый слот\nusersim_required_init_inform_keys = ['Release date']\n\n\n# То, что может запросить или передать агент\nagent_inform_slots = ['Release date','Max resolution','Low resolution','Effective pixels','Zoom tele (T)', 'Normal focus range', 'Macro focus range', 'Storage included', 'Weight (inc. batteries)', 'Dimensions', usersim_default_key]\nagent_request_slots = ['Release date','Max resolution','Low resolution','Effective pixels','Zoom wide (W)', 'Normal focus range', 'Macro focus range', 'Storage included', 'Weight (inc. batteries)', 'Dimensions', 'Price']\n\n# Доступные действия агента\nagent_actions = [\n    {'intent': 'done', 'inform_slots': {}, 'request_slots': {}},  # Triggers closing of conversation\n    {'intent': 'match_found', 'inform_slots': {}, 'request_slots': {}}\n]\nfor slot in agent_inform_slots:\n    if slot == usersim_default_key:\n        continue\n    agent_actions.append({'intent': 'inform', 'inform_slots': {slot: 'PLACEHOLDER'}, 'request_slots': {}})\nfor slot in agent_request_slots:\n    agent_actions.append({'intent': 'request', 'inform_slots': {}, 'request_slots': {slot: 'UNK'}})\n\n# Политика \nrule_requests = ['Release date','Max resolution','Low resolution', 'Effective pixels']\n\n# Не может быть запросов по этому ключу\nno_query_keys = ['Price', usersim_default_key]\n\n\n# Индикаторы успешности эпизода\nFAIL = -1\nNO_OUTCOME = 0\nSUCCESS = 1\n\n# все возможные намерения\nall_intents = ['inform', 'request', 'done', 'match_found', 'thanks', 'reject']\n\n# Все возможые слоты \nall_slots = ['Release date','Max resolution','Low resolution','Effective pixels','Zoom wide (W)','Zoom tele (T)','Normal focus range','Macro focus range','Storage included','Weight (inc. batteries)','Dimensions','Price', usersim_default_key]","metadata":{"execution":{"iopub.status.busy":"2023-05-12T17:55:39.853968Z","iopub.execute_input":"2023-05-12T17:55:39.854319Z","iopub.status.idle":"2023-05-12T17:55:39.866815Z","shell.execute_reply.started":"2023-05-12T17:55:39.854292Z","shell.execute_reply":"2023-05-12T17:55:39.865960Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"constants = {\n  \"db_file_paths\": {\n    \"database\": \"/kaggle/input/new-cam/cameras_db.pkl\",\n    \"dict\": \"/kaggle/input/new-cam/cameras_dict.pkl\",\n    \"user_goals\": \"/kaggle/input/000000/camera_user_goals.pkl\"\n  },\n  \"run\": {\n    \"usersim\": True,\n    \"warmup_mem\": 1000 ,\n    \"num_ep_run\": 5000,\n    \"train_freq\": 100,\n    \"max_round_num\": 20,\n    \"success_rate_threshold\": 0.3\n  },\n  \"agent\": {\n    \"save_weights_file_path\": \"\",\n    \"load_weights_file_path\": \"\",\n    \"vanilla\": True,\n    \"learning_rate\": 1e-3,\n    \"batch_size\": 16,\n    \"dqn_hidden_size\": 80,\n    \"epsilon_init\": 0.0,\n    \"gamma\": 0.9,\n    \"max_mem_size\": 500_000\n  },\n  \"emc\": {\n    \"slot_error_mode\": 0,\n    \"slot_error_prob\": 0.05,\n    \"intent_error_prob\": 0.0\n  }\n}","metadata":{"execution":{"iopub.status.busy":"2023-05-12T19:24:43.381472Z","iopub.execute_input":"2023-05-12T19:24:43.381936Z","iopub.status.idle":"2023-05-12T19:24:43.390629Z","shell.execute_reply.started":"2023-05-12T19:24:43.381901Z","shell.execute_reply":"2023-05-12T19:24:43.389460Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-05-12T17:55:39.891724Z","iopub.execute_input":"2023-05-12T17:55:39.892087Z","iopub.status.idle":"2023-05-12T17:55:39.907987Z","shell.execute_reply.started":"2023-05-12T17:55:39.892050Z","shell.execute_reply":"2023-05-12T17:55:39.906491Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def convert_list_to_dict(lst):\n\n\n    if len(lst) > len(set(lst)):\n        raise ValueError('List must be unique!')\n    return {k: v for v, k in enumerate(lst)}\n\n\ndef remove_empty_slots(dic):\n\n\n    for id in list(dic.keys()):\n        for key in list(dic[id].keys()):\n            if dic[id][key] == '':\n                dic[id].pop(key)\n\n\ndef reward_function(success, max_round):\n\n\n    reward = -1\n    if success == FAIL:\n        reward += -max_round\n    elif success == SUCCESS:\n        reward += 2 * max_round\n    return reward\n","metadata":{"execution":{"iopub.status.busy":"2023-05-12T17:55:39.910157Z","iopub.execute_input":"2023-05-12T17:55:39.910889Z","iopub.status.idle":"2023-05-12T17:55:39.925035Z","shell.execute_reply.started":"2023-05-12T17:55:39.910847Z","shell.execute_reply":"2023-05-12T17:55:39.924049Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class UserSimulator:\n \n    def __init__(self, goal_list, constants, database):\n\n\n        self.goal_list = goal_list\n        self.max_round = constants['run']['max_round_num']\n        self.default_key = usersim_default_key\n        self.init_informs = usersim_required_init_inform_keys\n        self.no_query = no_query_keys\n        self.database = database\n\n    def reset(self):\n\n\n        self.goal = random.choice(self.goal_list)\n        self.goal['request_slots'][self.default_key] = 'UNK'\n        self.state = {}\n        self.state['history_slots'] = {}\n        self.state['inform_slots'] = {}\n        self.state['request_slots'] = {}\n        self.state['rest_slots'] = {}\n        self.state['rest_slots'].update(self.goal['inform_slots'])\n        self.state['rest_slots'].update(self.goal['request_slots'])\n        self.state['intent'] = ''\n        self.constraint_check = FAIL\n\n        return self._return_init_action()\n\n    def _return_init_action(self):\n\n        self.state['intent'] = 'request'\n\n        if self.goal['inform_slots']:\n          \n            for inform_key in self.init_informs:\n                if inform_key in self.goal['inform_slots']:\n                    self.state['inform_slots'][inform_key] = self.goal['inform_slots'][inform_key]\n                    self.state['rest_slots'].pop(inform_key)\n                    self.state['history_slots'][inform_key] = self.goal['inform_slots'][inform_key]\n  \n            if not self.state['inform_slots']:\n                key, value = random.choice(list(self.goal['inform_slots'].items()))\n                self.state['inform_slots'][key] = value\n                self.state['rest_slots'].pop(key)\n                self.state['history_slots'][key] = value\n\n        self.goal['request_slots'].pop(self.default_key)\n        if self.goal['request_slots']:\n            req_key = random.choice(list(self.goal['request_slots'].keys()))\n        else:\n            req_key = self.default_key\n        self.goal['request_slots'][self.default_key] = 'UNK'\n        self.state['request_slots'][req_key] = 'UNK'\n\n        user_response = {}\n        user_response['intent'] = self.state['intent']\n        user_response['request_slots'] = copy.deepcopy(self.state['request_slots'])\n        user_response['inform_slots'] = copy.deepcopy(self.state['inform_slots'])\n\n        return user_response\n\n    def step(self, agent_action):\n\n\n        for value in agent_action['inform_slots'].values():\n            assert value != 'UNK'\n            assert value != 'PLACEHOLDER'\n\n        for value in agent_action['request_slots'].values():\n            assert value != 'PLACEHOLDER'\n\n\n        self.state['inform_slots'].clear()\n        self.state['intent'] = ''\n\n        done = False\n        success = NO_OUTCOME\n\n        if agent_action['round'] == self.max_round:\n            done = True\n            success = FAIL\n            self.state['intent'] = 'done'\n            self.state['request_slots'].clear()\n        else:\n            agent_intent = agent_action['intent']\n            if agent_intent == 'request':\n                self._response_to_request(agent_action)\n            elif agent_intent == 'inform':\n                self._response_to_inform(agent_action)\n            elif agent_intent == 'match_found':\n                self._response_to_match_found(agent_action)\n            elif agent_intent == 'done':\n                success = self._response_to_done()\n                self.state['intent'] = 'done'\n                self.state['request_slots'].clear()\n                done = True\n\n\n        if self.state['intent'] == 'request':\n            assert self.state['request_slots']\n\n        if self.state['intent'] == 'inform':\n            assert self.state['inform_slots']\n            assert not self.state['request_slots']\n        assert 'UNK' not in self.state['inform_slots'].values()\n        assert 'PLACEHOLDER' not in self.state['request_slots'].values()\n  \n        for key in self.state['rest_slots']:\n            assert key not in self.state['history_slots']\n        for key in self.state['history_slots']:\n            assert key not in self.state['rest_slots']\n    \n        for inf_key in self.goal['inform_slots']:\n            assert self.state['history_slots'].get(inf_key, False) or self.state['rest_slots'].get(inf_key, False)\n        for req_key in self.goal['request_slots']:\n            assert self.state['history_slots'].get(req_key, False) or self.state['rest_slots'].get(req_key,\n                                                                                                   False), req_key\n       \n        for key in self.state['rest_slots']:\n            assert self.goal['inform_slots'].get(key, False) or self.goal['request_slots'].get(key, False)\n        assert self.state['intent'] != ''\n\n\n        user_response = {}\n        user_response['intent'] = self.state['intent']\n        user_response['request_slots'] = copy.deepcopy(self.state['request_slots'])\n        user_response['inform_slots'] = copy.deepcopy(self.state['inform_slots'])\n\n        reward = reward_function(success, self.max_round)\n\n        return user_response, reward, done, True if success == 1 else False\n\n    def _response_to_request(self, agent_action):\n        agent_request_key = list(agent_action['request_slots'].keys())[0]\n   \n        if agent_request_key in self.goal['inform_slots']:\n            self.state['intent'] = 'inform'\n            self.state['inform_slots'][agent_request_key] = self.goal['inform_slots'][agent_request_key]\n            self.state['request_slots'].clear()\n            self.state['rest_slots'].pop(agent_request_key, None)\n            self.state['history_slots'][agent_request_key] = self.goal['inform_slots'][agent_request_key]\n\n        elif agent_request_key in self.goal['request_slots'] and agent_request_key in self.state['history_slots']:\n            self.state['intent'] = 'inform'\n            self.state['inform_slots'][agent_request_key] = self.state['history_slots'][agent_request_key]\n            self.state['request_slots'].clear()\n            assert agent_request_key not in self.state['rest_slots']\n    \n        elif agent_request_key in self.goal['request_slots'] and agent_request_key in self.state['rest_slots']:\n            self.state['request_slots'].clear()\n            self.state['intent'] = 'request'\n            self.state['request_slots'][agent_request_key] = 'UNK'\n            rest_informs = {}\n            for key, value in list(self.state['rest_slots'].items()):\n                if value != 'UNK':\n                    rest_informs[key] = value\n            if rest_informs:\n                key_choice, value_choice = random.choice(list(rest_informs.items()))\n                self.state['inform_slots'][key_choice] = value_choice\n                self.state['rest_slots'].pop(key_choice)\n                self.state['history_slots'][key_choice] = value_choice\n      \n        else:\n            assert agent_request_key not in self.state['rest_slots']\n            self.state['intent'] = 'inform'\n            self.state['inform_slots'][agent_request_key] = 'anything'\n            self.state['request_slots'].clear()\n            self.state['history_slots'][agent_request_key] = 'anything'\n\n    def _response_to_inform(self, agent_action):\n\n\n        agent_inform_key = list(agent_action['inform_slots'].keys())[0]\n        agent_inform_value = agent_action['inform_slots'][agent_inform_key]\n\n        assert agent_inform_key != self.default_key\n        self.state['history_slots'][agent_inform_key] = agent_inform_value\n        self.state['rest_slots'].pop(agent_inform_key, None)\n\n        self.state['request_slots'].pop(agent_inform_key, None)\n\n        if agent_inform_value != self.goal['inform_slots'].get(agent_inform_key, agent_inform_value):\n            self.state['intent'] = 'inform'\n            self.state['inform_slots'][agent_inform_key] = self.goal['inform_slots'][agent_inform_key]\n            self.state['request_slots'].clear()\n            self.state['history_slots'][agent_inform_key] = self.goal['inform_slots'][agent_inform_key]\n        else:\n            if self.state['request_slots']:\n                self.state['intent'] = 'request'\n            elif self.state['rest_slots']:\n                def_in = self.state['rest_slots'].pop(self.default_key, False)\n                if self.state['rest_slots']:\n                    key, value = random.choice(list(self.state['rest_slots'].items()))\n                    if value != 'UNK':\n                        self.state['intent'] = 'inform'\n                        self.state['inform_slots'][key] = value\n                        self.state['rest_slots'].pop(key)\n                        self.state['history_slots'][key] = value\n                    else:\n                        self.state['intent'] = 'request'\n                        self.state['request_slots'][key] = 'UNK'\n                else:\n                    self.state['intent'] = 'request'\n                    self.state['request_slots'][self.default_key] = 'UNK'\n                if def_in == 'UNK':\n                    self.state['rest_slots'][self.default_key] = 'UNK'\n            else:\n                self.state['intent'] = 'thanks'\n\n    def _response_to_match_found(self, agent_action):\n\n\n        agent_informs = agent_action['inform_slots']\n\n        self.state['intent'] = 'thanks'\n        self.constraint_check = SUCCESS\n\n        assert self.default_key in agent_informs\n        self.state['rest_slots'].pop(self.default_key, None)\n        self.state['history_slots'][self.default_key] = str(agent_informs[self.default_key])\n        self.state['request_slots'].pop(self.default_key, None)\n\n        if agent_informs[self.default_key] == 'no match available':\n            self.constraint_check = FAIL\n        for key, value in self.goal['inform_slots'].items():\n            assert value != None\n\n            if key in self.no_query:\n                continue\n\n            if value != agent_informs.get(key, None):\n                self.constraint_check = FAIL\n                break\n\n        if self.constraint_check == FAIL:\n            self.state['intent'] = 'reject'\n            self.state['request_slots'].clear()\n\n    def _response_to_done(self):\n\n\n        if self.constraint_check == FAIL:\n            return FAIL\n\n        if not self.state['rest_slots']:\n            assert not self.state['request_slots']\n        if self.state['rest_slots']:\n            return FAIL\n\n\n        assert self.state['history_slots'][self.default_key] != 'no match available'\n\n        match = copy.deepcopy(self.database[int(self.state['history_slots'][self.default_key])])\n\n        for key, value in self.goal['inform_slots'].items():\n            assert value != None\n            if key in self.no_query:\n                continue\n            if value != match.get(key, None):\n                assert True is False, 'match: {}\\ngoal: {}'.format(match, self.goal)\n                break\n\n\n        return SUCCESS","metadata":{"execution":{"iopub.status.busy":"2023-05-12T17:55:39.926538Z","iopub.execute_input":"2023-05-12T17:55:39.927147Z","iopub.status.idle":"2023-05-12T17:55:39.987328Z","shell.execute_reply.started":"2023-05-12T17:55:39.927103Z","shell.execute_reply":"2023-05-12T17:55:39.985900Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"\nclass DQNAgent:\n  \n\n    def __init__(self, state_size, constants):\n        \"\"\"\n       Конструктор класса агента, сохранящий главные константы \n        \"\"\"\n        self.C = constants['agent']\n        self.memory = []\n        self.memory_index = 0\n        self.max_memory_size = self.C['max_mem_size']\n        self.eps = self.C['epsilon_init']\n        self.vanilla = self.C['vanilla']\n        self.lr = self.C['learning_rate']\n        self.gamma = self.C['gamma']\n        self.batch_size = self.C['batch_size']\n        self.hidden_size = self.C['dqn_hidden_size']\n        \n        self.load_weights_file_path = self.C['load_weights_file_path']\n        self.save_weights_file_path = self.C['save_weights_file_path']\n        self.device = device\n        if self.max_memory_size < self.batch_size:\n            raise ValueError('Max memory size must be at least as great as batch size!')\n\n        self.state_size = state_size\n        self.possible_actions = agent_actions\n        self.num_actions = len(self.possible_actions)\n        self.rule_request_set = rule_requests\n        self.beh_model = self._build_model()\n        self.tar_model = self._build_model()\n        self.optim = Adam(self.beh_model.parameters(), lr=self.lr)\n        self.criterion=MSELoss()\n\n        self._load_weights()\n\n        self.reset()\n\n\n    \n    def _build_model(self):\n        \"\"\"Построение однослойной модели\"\"\"\n\n        model = Sequential(\n            Linear(self.state_size, self.hidden_size, dtype=float),\n            ReLU(),\n            Linear(self.hidden_size, self.num_actions, dtype=float)\n        )\n        \n        return model.to(self.device)\n    \n    \n    def reset(self):\n\n        self.rule_current_slot_index = 0\n        self.rule_phase = 'not done'\n\n    def get_action(self, state, use_rule=False):\n\n        if self.eps > random.random():\n            index = random.randint(0, self.num_actions - 1)\n            action = self._map_index_to_action(index)\n            return index, action\n        else:\n            if use_rule:\n                return self._rule_action()\n            else:\n                return self._dqn_action(state)\n\n    def _rule_action(self):\n\n        if self.rule_current_slot_index < len(self.rule_request_set):\n            slot = self.rule_request_set[self.rule_current_slot_index]\n            self.rule_current_slot_index += 1\n            rule_response = {'intent': 'request', 'inform_slots': {}, 'request_slots': {slot: 'UNK'}}\n        elif self.rule_phase == 'not done':\n            rule_response = {'intent': 'match_found', 'inform_slots': {}, 'request_slots': {}}\n            self.rule_phase = 'done'\n        elif self.rule_phase == 'done':\n            rule_response = {'intent': 'done', 'inform_slots': {}, 'request_slots': {}}\n        else:\n            raise Exception('Should not have reached this clause')\n\n        index = self._map_action_to_index(rule_response)\n        return index, rule_response\n\n    def _map_action_to_index(self, response):\n\n        for (i, action) in enumerate(self.possible_actions):\n            if response == action:\n                return i\n        raise ValueError('Response: {} not found in possible actions'.format(response))\n\n    def _dqn_action(self, state):\n\n        index = np.argmax(self._dqn_predict_one(state))\n        action = self._map_index_to_action(index)\n        return index, action\n\n    def _map_index_to_action(self, index):\n\n\n        for (i, action) in enumerate(self.possible_actions):\n            if index == i:\n                return copy.deepcopy(action)\n        raise ValueError('Index: {} not in range of possible actions'.format(index))\n\n    def _dqn_predict_one(self, state, target=False):\n\n        return self._dqn_predict(state.reshape(1, self.state_size), target=target).flatten()\n\n\n    \n    \n    \n    def _dqn_predict(self, states, target=False):\n        \"\"\"\n Функция, возвращающая предсказываемую Q-функцию, основываясь на состоянии\n        \"\"\"\n\n        model = self.tar_model if target else self.beh_model\n        return model(torch.tensor(states, dtype=float, device=self.device)).detach().cpu().numpy()\n    \n\n\n\n    def add_experience(self, state, action, reward, next_state, done):\n\n        if len(self.memory) < self.max_memory_size:\n            self.memory.append(None)\n        self.memory[self.memory_index] = (state, action, reward, next_state, done)\n        self.memory_index = (self.memory_index + 1) % self.max_memory_size\n\n    def empty_memory(self):\n\n        self.memory = []\n        self.memory_index = 0\n\n    def is_memory_full(self):\n\n\n        return len(self.memory) == self.max_memory_size\n\n    def train(self):\n\n        num_batches = len(self.memory) // self.batch_size\n        for b in range(num_batches):\n            batch = random.sample(self.memory, self.batch_size)\n\n            states = np.array([sample[0] for sample in batch])\n            next_states = np.array([sample[3] for sample in batch])\n\n            assert states.shape == (self.batch_size, self.state_size), 'States Shape: {}'.format(states.shape)\n            assert next_states.shape == states.shape\n\n            beh_state_preds = self._dqn_predict(states) \n            if not self.vanilla:\n                beh_next_states_preds = self._dqn_predict(next_states)  \n            tar_next_state_preds = self._dqn_predict(next_states, target=True) \n\n            inputs = np.zeros((self.batch_size, self.state_size))\n            targets = np.zeros((self.batch_size, self.num_actions))\n\n            for i, (s, a, r, s_, d) in enumerate(batch):\n                t = beh_state_preds[i]\n                if not self.vanilla:\n                    t[a] = r + self.gamma * tar_next_state_preds[i][np.argmax(beh_next_states_preds[i])] * (not d)\n                else:\n                    t[a] = r + self.gamma * np.amax(tar_next_state_preds[i]) * (not d)\n\n                inputs[i] = s\n                targets[i] = t\n\n            self.beh_model.train()\n            batch_size = 32\n            for ix in range(0, len(inputs), batch_size):\n                batch_inputs = inputs[ix:ix+batch_size]\n                batch_target = targets[ix:ix+batch_size]\n\n                preds = self.beh_model(torch.tensor(batch_inputs, dtype=float, device=self.device))\n                loss = self.criterion(torch.tensor(batch_target, dtype=float, device=self.device), preds)\n\n                self.optim.zero_grad()\n                loss.backward()\n\n                self.optim.step()\n    \n    def copy(self):\n\n        self.tar_model.load_state_dict(self.beh_model.state_dict())\n\n    def save_weights(self):\n\n        if not self.save_weights_file_path:\n            return\n        beh_save_file_path = re.sub(r'\\.h5', r'_beh.h5', self.save_weights_file_path)\n        self.beh_model.save_weights(beh_save_file_path)\n        tar_save_file_path = re.sub(r'\\.h5', r'_tar.h5', self.save_weights_file_path)\n        self.tar_model.save_weights(tar_save_file_path)\n\n    def _load_weights(self):\n       \n\n        if not self.load_weights_file_path:\n            return\n        beh_load_file_path = re.sub(r'\\.h5', r'_beh.h5', self.load_weights_file_path)\n        self.beh_model.load_weights(beh_load_file_path)\n        tar_load_file_path = re.sub(r'\\.h5', r'_tar.h5', self.load_weights_file_path)\n        self.tar_model.load_weights(tar_load_file_path)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-12T18:30:14.474677Z","iopub.execute_input":"2023-05-12T18:30:14.475316Z","iopub.status.idle":"2023-05-12T18:30:14.525154Z","shell.execute_reply.started":"2023-05-12T18:30:14.475281Z","shell.execute_reply":"2023-05-12T18:30:14.523719Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"import random\n\n\nclass ErrorModelController:\n\n    def __init__(self, db_dict, constants):\n\n        self.movie_dict = db_dict\n        self.slot_error_prob = constants['emc']['slot_error_prob']\n        self.slot_error_mode = constants['emc']['slot_error_mode']  # [0, 3]\n        self.intent_error_prob = constants['emc']['intent_error_prob']\n        self.intents = usersim_intents\n\n    def infuse_error(self, frame):\n\n        informs_dict = frame['inform_slots']\n        for key in list(frame['inform_slots'].keys()):\n            assert key in self.movie_dict\n            if random.random() < self.slot_error_prob:\n                if self.slot_error_mode == 0: \n                    self._slot_value_noise(key, informs_dict)\n                elif self.slot_error_mode == 1: \n                    self._slot_noise(key, informs_dict)\n                elif self.slot_error_mode == 2:  \n                    self._slot_remove(key, informs_dict)\n                else:  \n                    rand_choice = random.random()\n                    if rand_choice <= 0.33:\n                        self._slot_value_noise(key, informs_dict)\n                    elif rand_choice > 0.33 and rand_choice <= 0.66:\n                        self._slot_noise(key, informs_dict)\n                    else:\n                        self._slot_remove(key, informs_dict)\n        if random.random() < self.intent_error_prob:\n            frame['intent'] = random.choice(self.intents)\n\n    def _slot_value_noise(self, key, informs_dict):\n\n        informs_dict[key] = random.choice(self.movie_dict[key])\n\n    def _slot_noise(self, key, informs_dict):\n        informs_dict.pop(key)\n        random_slot = random.choice(list(self.movie_dict.keys()))\n        informs_dict[random_slot] = random.choice(self.movie_dict[random_slot])\n\n    def _slot_remove(self, key, informs_dict):\n\n\n        informs_dict.pop(key)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-12T18:30:16.370969Z","iopub.execute_input":"2023-05-12T18:30:16.371389Z","iopub.status.idle":"2023-05-12T18:30:16.387406Z","shell.execute_reply.started":"2023-05-12T18:30:16.371359Z","shell.execute_reply":"2023-05-12T18:30:16.386216Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"class DBQuery:\n    def __init__(self, database):\n\n        self.database = database\n        self.cached_db_slot = defaultdict(dict)\n        self.cached_db = defaultdict(dict)\n        self.no_query = no_query_keys\n        self.match_key = usersim_default_key\n\n    def fill_inform_slot(self, inform_slot_to_fill, current_inform_slots):\n\n        assert len(inform_slot_to_fill) == 1\n\n        key = list(inform_slot_to_fill.keys())[0]\n\n        current_informs = copy.deepcopy(current_inform_slots)\n        current_informs.pop(key, None)\n\n        db_results = self.get_db_results(current_informs)\n\n        filled_inform = {}\n        values_dict = self._count_slot_values(key, db_results)\n        if values_dict:\n\n            filled_inform[key] = max(values_dict, key=values_dict.get)\n        else:\n            filled_inform[key] = 'no match available'\n\n        return filled_inform\n\n    def _count_slot_values(self, key, db_subdict):\n        slot_values = defaultdict(int)  # init to 0\n        for id in db_subdict.keys():\n            current_option_dict = db_subdict[id]\n            if key in current_option_dict.keys():\n                slot_value = current_option_dict[key]\n                slot_values[slot_value] += 1\n        return slot_values\n\n    def get_db_results(self, constraints):\n\n        new_constraints = {k: v for k, v in constraints.items() if k not in self.no_query and v != 'anything'}\n\n        inform_items = frozenset(new_constraints.items())\n        cache_return = self.cached_db[inform_items]\n\n        if cache_return == None:\n            return {}\n        if cache_return:\n            return cache_return\n\n\n        available_options = {}\n        for id in self.database.keys():\n            current_option_dict = self.database[id]\n\n            if len(set(new_constraints.keys()) - set(self.database[id].keys())) == 0:\n                match = True\n                for k, v in new_constraints.items():\n                    if str(v).lower() != str(current_option_dict[k]).lower():\n                        match = False\n                if match:\n\n                    self.cached_db[inform_items].update({id: current_option_dict})\n                    available_options.update({id: current_option_dict})\n\n        if not available_options:\n            self.cached_db[inform_items] = None\n\n        return available_options\n\n    def get_db_results_for_slots(self, current_informs):\n        inform_items = frozenset(current_informs.items())\n        cache_return = self.cached_db_slot[inform_items]\n\n        if cache_return:\n            return cache_return\n        db_results = {key: 0 for key in current_informs.keys()}\n        db_results['matching_all_constraints'] = 0\n\n        for id in self.database.keys():\n            all_slots_match = True\n            for CI_key, CI_value in current_informs.items():\n                if CI_key in self.no_query:\n                    continue\n                if CI_value == 'anything':\n                    db_results[CI_key] += 1\n                    continue\n                if CI_key in self.database[id].keys():\n                    if CI_value.lower() == self.database[id][CI_key].lower():\n                        db_results[CI_key] += 1\n                    else:\n                        all_slots_match = False\n                else:\n                    all_slots_match = False\n            if all_slots_match: db_results['matching_all_constraints'] += 1\n\n        self.cached_db_slot[inform_items].update(db_results)\n        assert self.cached_db_slot[inform_items] == db_results\n        return db_results\n","metadata":{"execution":{"iopub.status.busy":"2023-05-12T17:55:40.052351Z","iopub.execute_input":"2023-05-12T17:55:40.052875Z","iopub.status.idle":"2023-05-12T17:55:40.077759Z","shell.execute_reply.started":"2023-05-12T17:55:40.052791Z","shell.execute_reply":"2023-05-12T17:55:40.076346Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class StateTracker:\n\n    def __init__(self, database, constants):\n\n\n        self.db_helper = DBQuery(database)\n        self.match_key = usersim_default_key\n        self.intents_dict = convert_list_to_dict(all_intents)\n        self.num_intents = len(all_intents)\n        self.slots_dict = convert_list_to_dict(all_slots)\n        self.num_slots = len(all_slots)\n        self.max_round_num = constants['run']['max_round_num']\n        self.none_state = np.zeros(self.get_state_size())\n        self.reset()\n\n    def get_state_size(self):\n\n        return 2 * self.num_intents + 7 * self.num_slots + 3 + self.max_round_num\n\n    def reset(self):\n\n        self.current_informs = {}\n        self.history = []\n        self.round_num = 0\n\n    def print_history(self):\n\n        for action in self.history:\n            print(action)\n\n    def get_state(self, done=False):\n\n        if done:\n            return self.none_state\n\n        user_action = self.history[-1]\n        db_results_dict = self.db_helper.get_db_results_for_slots(self.current_informs)\n        last_agent_action = self.history[-2] if len(self.history) > 1 else None\n\n        user_act_rep = np.zeros((self.num_intents,))\n        user_act_rep[self.intents_dict[user_action['intent']]] = 1.0\n\n        user_inform_slots_rep = np.zeros((self.num_slots,))\n        for key in user_action['inform_slots'].keys():\n            user_inform_slots_rep[self.slots_dict[key]] = 1.0\n\n        user_request_slots_rep = np.zeros((self.num_slots,))\n        for key in user_action['request_slots'].keys():\n            user_request_slots_rep[self.slots_dict[key]] = 1.0\n\n        current_slots_rep = np.zeros((self.num_slots,))\n        for key in self.current_informs:\n            current_slots_rep[self.slots_dict[key]] = 1.0\n\n        agent_act_rep = np.zeros((self.num_intents,))\n        if last_agent_action:\n            agent_act_rep[self.intents_dict[last_agent_action['intent']]] = 1.0\n\n        agent_inform_slots_rep = np.zeros((self.num_slots,))\n        if last_agent_action:\n            for key in last_agent_action['inform_slots'].keys():\n                agent_inform_slots_rep[self.slots_dict[key]] = 1.0\n\n        agent_request_slots_rep = np.zeros((self.num_slots,))\n        if last_agent_action:\n            for key in last_agent_action['request_slots'].keys():\n                agent_request_slots_rep[self.slots_dict[key]] = 1.0\n\n        turn_rep = np.zeros((1,)) + self.round_num / 5.\n\n        turn_onehot_rep = np.zeros((self.max_round_num,))\n        turn_onehot_rep[self.round_num - 1] = 1.0\n\n        kb_count_rep = np.zeros((self.num_slots + 1,)) + db_results_dict['matching_all_constraints'] / 100.\n        for key in db_results_dict.keys():\n            if key in self.slots_dict:\n                kb_count_rep[self.slots_dict[key]] = db_results_dict[key] / 100.\n\n        kb_binary_rep = np.zeros((self.num_slots + 1,)) + np.sum(db_results_dict['matching_all_constraints'] > 0.)\n        for key in db_results_dict.keys():\n            if key in self.slots_dict:\n                kb_binary_rep[self.slots_dict[key]] = np.sum(db_results_dict[key] > 0.)\n\n        state_representation = np.hstack(\n            [user_act_rep, user_inform_slots_rep, user_request_slots_rep, agent_act_rep, agent_inform_slots_rep,\n             agent_request_slots_rep, current_slots_rep, turn_rep, turn_onehot_rep, kb_binary_rep,\n             kb_count_rep]).flatten()\n\n        return state_representation\n\n    def update_state_agent(self, agent_action):\n        if agent_action['intent'] == 'inform':\n            assert agent_action['inform_slots']\n            inform_slots = self.db_helper.fill_inform_slot(agent_action['inform_slots'], self.current_informs)\n            agent_action['inform_slots'] = inform_slots\n            assert agent_action['inform_slots']\n            key, value = list(agent_action['inform_slots'].items())[0]  # Only one\n            assert key != 'match_found'\n            assert value != 'PLACEHOLDER', 'KEY: {}'.format(key)\n            self.current_informs[key] = value\n\n        elif agent_action['intent'] == 'match_found':\n            assert not agent_action['inform_slots'], 'Cannot inform and have intent of match found!'\n            db_results = self.db_helper.get_db_results(self.current_informs)\n            if db_results:\n\n                key, value = list(db_results.items())[0]\n                agent_action['inform_slots'] = copy.deepcopy(value)\n                agent_action['inform_slots'][self.match_key] = str(key)\n            else:\n                agent_action['inform_slots'][self.match_key] = 'no match available'\n            self.current_informs[self.match_key] = agent_action['inform_slots'][self.match_key]\n        agent_action.update({'round': self.round_num, 'speaker': 'Agent'})\n        self.history.append(agent_action)\n\n    def update_state_user(self, user_action):\n\n        for key, value in user_action['inform_slots'].items():\n            self.current_informs[key] = value\n        user_action.update({'round': self.round_num, 'speaker': 'User'})\n        self.history.append(user_action)\n        self.round_num += 1\n","metadata":{"execution":{"iopub.status.busy":"2023-05-12T17:55:40.079419Z","iopub.execute_input":"2023-05-12T17:55:40.080279Z","iopub.status.idle":"2023-05-12T17:55:40.111180Z","shell.execute_reply.started":"2023-05-12T17:55:40.080247Z","shell.execute_reply":"2023-05-12T17:55:40.109891Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"wandb.login()","metadata":{"execution":{"iopub.status.busy":"2023-05-12T17:55:40.112885Z","iopub.execute_input":"2023-05-12T17:55:40.113412Z","iopub.status.idle":"2023-05-12T17:56:19.997004Z","shell.execute_reply.started":"2023-05-12T17:55:40.113380Z","shell.execute_reply":"2023-05-12T17:56:19.994255Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"run = wandb.init(\n    project=\"cource\",\n    config=constants)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-12T19:46:58.269760Z","iopub.execute_input":"2023-05-12T19:46:58.271446Z","iopub.status.idle":"2023-05-12T19:47:35.840431Z","shell.execute_reply.started":"2023-05-12T19:46:58.271386Z","shell.execute_reply":"2023-05-12T19:47:35.839574Z"},"trusted":true},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:3sots9og) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_reward</td><td>▁▃▆▆▄▇▃▅▄▇▇▅▅▅█▅▆▅▇█▇▇▇▆▇▇▇▃▆▇▆▇▆▅▆█▆▅▇▆</td></tr><tr><td>avg_reward_test</td><td>█▁██████████████▁█████▁█▁█████████▁██▁██</td></tr><tr><td>success_rate</td><td>▁▁▅▆▃▇▃▅▄▇▆▄▅▅█▅▆▅▇█▆▆▆▆▇▇▇▃▆▆▆▆▆▅▆█▆▅▆▆</td></tr><tr><td>success_rate_test</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_reward</td><td>8.3</td></tr><tr><td>avg_reward_test</td><td>-2.1</td></tr><tr><td>success_rate</td><td>0.6</td></tr><tr><td>success_rate_test</td><td>0.0</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">bright-capybara-3</strong> at: <a href='https://wandb.ai/ksenia_team/cource/runs/3sots9og' target=\"_blank\">https://wandb.ai/ksenia_team/cource/runs/3sots9og</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20230512_192329-3sots9og/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:3sots9og). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230512_194658-wsz73mij</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ksenia_team/cource/runs/wsz73mij' target=\"_blank\">astral-frog-4</a></strong> to <a href='https://wandb.ai/ksenia_team/cource' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ksenia_team/cource' target=\"_blank\">https://wandb.ai/ksenia_team/cource</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ksenia_team/cource/runs/wsz73mij' target=\"_blank\">https://wandb.ai/ksenia_team/cource/runs/wsz73mij</a>"},"metadata":{}}]},{"cell_type":"code","source":"import pickle, argparse, json, math\n\n\nif __name__ == \"__main__\":\n\n    file_path_dict = constants['db_file_paths']\n    DATABASE_FILE_PATH = file_path_dict['database']\n    DICT_FILE_PATH = file_path_dict['dict']\n    USER_GOALS_FILE_PATH = file_path_dict['user_goals']\n\n    run_dict = constants['run']\n    USE_USERSIM = run_dict['usersim']\n    WARMUP_MEM = run_dict['warmup_mem']\n    NUM_EP_TRAIN = run_dict['num_ep_run']\n    TRAIN_FREQ = run_dict['train_freq']\n    MAX_ROUND_NUM = run_dict['max_round_num']\n    SUCCESS_RATE_THRESHOLD = run_dict['success_rate_threshold']\n\n    database = pickle.load(open(DATABASE_FILE_PATH, 'rb'), encoding='latin1')\n\n\n\n\n    db_dict = pickle.load(open(DICT_FILE_PATH, 'rb'), encoding='latin1')\n\n   \n    user_goals = pickle.load(open(USER_GOALS_FILE_PATH, 'rb'), encoding='latin1')\n\n\n    if USE_USERSIM:\n        user = UserSimulator(user_goals, constants, database)\n    else:\n        user = User(constants)\n    emc = ErrorModelController(db_dict, constants)\n    state_tracker = StateTracker(database, constants)\n    dqn_agent = DQNAgent(state_tracker.get_state_size(), constants)\n\n\ndef run_round(state, warmup=False):\n    agent_action_index, agent_action = dqn_agent.get_action(state, use_rule=warmup)\n    #print('AgAct', agent_action)\n    state_tracker.update_state_agent(agent_action)\n    user_action, reward, done, success = user.step(agent_action)\n    #print('UsAct', user_action)\n    if not done:\n  \n        emc.infuse_error(user_action)\n\n    state_tracker.update_state_user(user_action)\n\n    next_state = state_tracker.get_state(done)\n    dqn_agent.add_experience(state, agent_action_index, reward, next_state, done)\n\n    return next_state, reward, done, success\n\n\ndef warmup_run():\n\n    print('Warmup Started...')\n    total_step = 0\n    progress_bar = tqdm(total=WARMUP_MEM)\n    while total_step < WARMUP_MEM and not dqn_agent.is_memory_full():\n\n        episode_reset()\n        done = False\n\n        state = state_tracker.get_state()\n        while not done:\n            next_state, _, done, _ = run_round(state, warmup=True)\n            total_step += 1\n            state = next_state\n            progress_bar.update(1)\n\n    print('...Warmup Ended')\n\n\ndef train_run():\n\n    print('Training Started...')\n    episode = 0\n    period_reward_total = 0\n    period_success_total = 0\n    success_rate_best = 0.0\n    progress_bar = tqdm(total=NUM_EP_TRAIN)\n    while episode < NUM_EP_TRAIN:\n        episode_reset()\n        episode += 1\n        progress_bar.update(1)\n        done = False\n        state = state_tracker.get_state()\n        while not done:\n            next_state, reward, done, success = run_round(state)\n            #print(user.action)\n            period_reward_total += reward\n            state = next_state\n\n        period_success_total += success\n        \n        if episode % 10 == 0:\n            wandb.log({\"success_rate\": period_success_total / 10, 'avg_reward': period_reward_total / 10})\n            period_success_total = 0\n            period_reward_total = 0\n        if episode % TRAIN_FREQ == 0:\n            success_rate = period_success_total / TRAIN_FREQ\n            avg_reward = period_reward_total / TRAIN_FREQ\n            if success_rate >= success_rate_best and success_rate >= SUCCESS_RATE_THRESHOLD:\n                dqn_agent.empty_memory()\n\n            if success_rate > success_rate_best:\n                success_rate_best = success_rate\n                dqn_agent.save_weights()\n            period_success_total = 0\n            period_reward_total = 0\n            dqn_agent.copy()\n            dqn_agent.train()\n    print(period_success_total)\n    print('...Training Ended')\n\n\ndef episode_reset():\n    state_tracker.reset()\n    user_action = user.reset()\n    emc.infuse_error(user_action)\n    state_tracker.update_state_user(user_action)\n    dqn_agent.reset()\n\n    \n\nwarmup_run()\ntrain_run()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-12T19:24:50.766474Z","iopub.execute_input":"2023-05-12T19:24:50.766874Z","iopub.status.idle":"2023-05-12T19:26:48.256191Z","shell.execute_reply.started":"2023-05-12T19:24:50.766845Z","shell.execute_reply":"2023-05-12T19:26:48.254641Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Warmup Started...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"101243308f004a72afd61365726e8f15"}},"metadata":{}},{"name":"stdout","text":"...Warmup Ended\nTraining Started...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58a97739e9f74dfb978b1bb4b8f62372"}},"metadata":{}},{"name":"stdout","text":"0\n...Training Ended\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"constants = {\n  \"db_file_paths\": {\n    \"database\": \"/kaggle/input/test-cam/cameras_db_test.pkl\",\n    \"dict\": \"/kaggle/input/testt-cam/cameras_dict_test.pkl\",\n    \"user_goals\": \"/kaggle/input/test-cam/camera_user_goals_test.pkl\"\n  },\n  \"run\": {\n    \"usersim\": True,\n    \"warmup_mem\": 1000 ,\n    \"num_ep_run\": 5000,\n    \"train_freq\": 100,\n    \"max_round_num\": 20,\n    \"success_rate_threshold\": 0.3\n  },\n  \"agent\": {\n    \"save_weights_file_path\": \"\",\n    \"load_weights_file_path\": \"\",\n    \"vanilla\": True,\n    \"learning_rate\": 1e-3,\n    \"batch_size\": 16,\n    \"dqn_hidden_size\": 80,\n    \"epsilon_init\": 0.0,\n    \"gamma\": 0.9,\n    \"max_mem_size\": 500_000\n  },\n  \"emc\": {\n    \"slot_error_mode\": 0,\n    \"slot_error_prob\": 0.05,\n    \"intent_error_prob\": 0.0\n  }\n}","metadata":{"execution":{"iopub.status.busy":"2023-05-12T19:43:04.174146Z","iopub.execute_input":"2023-05-12T19:43:04.174573Z","iopub.status.idle":"2023-05-12T19:43:04.182522Z","shell.execute_reply.started":"2023-05-12T19:43:04.174540Z","shell.execute_reply":"2023-05-12T19:43:04.181109Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"\n\nif __name__ == \"__main__\":\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--constants_path', dest='constants_path', type=str, default='')\n    args, unknown = parser.parse_known_args()\n    params = vars(args)\n\n    \n    file_path_dict = constants['db_file_paths']\n    DATABASE_FILE_PATH = file_path_dict['database']\n    DICT_FILE_PATH = file_path_dict['dict']\n    USER_GOALS_FILE_PATH = file_path_dict['user_goals']\n\n    run_dict = constants['run']\n    USE_USERSIM = run_dict['usersim']\n    NUM_EP_TEST = run_dict['num_ep_run']\n    MAX_ROUND_NUM = run_dict['max_round_num']\n\n\n    database = pickle.load(open(DATABASE_FILE_PATH, 'rb'), encoding='latin1')\n\n    remove_empty_slots(database)\n\n    db_dict = pickle.load(open(DICT_FILE_PATH, 'rb'), encoding='latin1')\n\n    user_goals = pickle.load(open(USER_GOALS_FILE_PATH, 'rb'), encoding='latin1')\n\n    if USE_USERSIM:\n        user = UserSimulator(user_goals, constants, database)\n    else:\n        user = User(constants)\n    emc = ErrorModelController(db_dict, constants)\n    state_tracker = StateTracker(database, constants)\n    dqn_agent = DQNAgent(state_tracker.get_state_size(), constants)\n\n\ndef test_run():\n   \n\n    print('Testing Started...')\n    episode = 0\n    while episode < NUM_EP_TEST:\n        episode_reset()\n        episode += 1\n        ep_reward = 0\n        \n        success_total=0\n        \n        done = False\n        state = state_tracker.get_state()\n        while not done:\n       \n            agent_action_index, agent_action = dqn_agent.get_action(state)\n    \n            state_tracker.update_state_agent(agent_action)\n   \n            user_action, reward, done, success = user.step(agent_action)\n            ep_reward += reward\n            success_total+=success\n            \n            if episode % 10 == 0:\n                wandb.log({\"success_rate_test\": success_total / 10, 'avg_reward_test': ep_reward / 10})\n                ep_reward = 0\n            if not done:\n                emc.infuse_error(user_action)\n            state_tracker.update_state_user(user_action)\n            state = state_tracker.get_state(done)\n#         print('Episode: {} Success: {} Reward: {}'.format(episode, success, ep_reward))\n#         print('Действие пользователя:{}'.format(user_action))\n#         print('Действие агента:{}'.format(agent_action))\n        \n    print('...Testing Ended')\n\n\ndef episode_reset():\n\n    state_tracker.reset()\n    user_action = user.reset()\n    emc.infuse_error(user_action)\n    state_tracker.update_state_user(user_action)\n    dqn_agent.reset()\n\n\ntest_run()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-12T19:43:04.729106Z","iopub.execute_input":"2023-05-12T19:43:04.729657Z","iopub.status.idle":"2023-05-12T19:43:39.414680Z","shell.execute_reply.started":"2023-05-12T19:43:04.729611Z","shell.execute_reply":"2023-05-12T19:43:39.413091Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Testing Started...\n...Testing Ended\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}